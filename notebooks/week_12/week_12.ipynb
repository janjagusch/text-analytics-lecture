{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from numpy import dot, sqrt, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cooccurrence_matrix(corpus):\n",
    "    \"\"\"\n",
    "    Create the co-occurrence matrix.\n",
    "\n",
    "    Input\n",
    "    corpus (tuple of tuples) -- tokenized texts\n",
    "\n",
    "    Output\n",
    "    d -- a two-dimensional defaultdict mapping word pairs to counts\n",
    "    \"\"\"    \n",
    "    d = defaultdict(lambda : defaultdict(int))\n",
    "    for text in corpus:\n",
    "        for i in range(len(text)-1):            \n",
    "            for j in range(i+1, len(text)):\n",
    "                w1, w2 = sorted([text[i], text[j]])                \n",
    "                d[w1][w2] += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sorted_vocab(d):\n",
    "    \"\"\"\n",
    "    Sort the entire vocabulary (keys and keys of their value\n",
    "    dictionaries).\n",
    "\n",
    "    Input\n",
    "    d -- dictionary mapping word-pairs to counts, created by\n",
    "         cooccurrence_matrix(). We need only the keys for this step.\n",
    "\n",
    "    Output\n",
    "    vocab -- sorted list of strings\n",
    "    \"\"\"\n",
    "    vocab = set([])\n",
    "    for w1, val_dict in d.items():\n",
    "        vocab.add(w1)\n",
    "        for w2 in val_dict.keys():\n",
    "            vocab.add(w2)\n",
    "    vocab = sorted(list(vocab))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_matrix(vocab, d):\n",
    "    \"\"\"\n",
    "    Create the cosine similarity matrix.\n",
    "\n",
    "    Input\n",
    "    vocab -- a list of words derived from the keys of d\n",
    "    d -- a two-dimensional defaultdict mapping word pairs to counts,\n",
    "    as created by cooccurrence_matrix()\n",
    "\n",
    "    Output\n",
    "    cm -- a two-dimensional defaultdict mapping word pairs to their\n",
    "    cosine similarity according to d    \n",
    "    \"\"\"\n",
    "    cm = defaultdict(dict)\n",
    "    vectors = get_vectors(d, vocab)\n",
    "    for w1 in vocab:\n",
    "        for w2 in vocab:\n",
    "            cm[w1][w2] = cosim(vectors[w1], vectors[w2])\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vectors(d, vocab):\n",
    "    \"\"\"\n",
    "    Interate through the vocabulary, creating the vector for each word\n",
    "    in it.\n",
    "\n",
    "    Input\n",
    "    d -- dictionary mapping word-pairs to counts, created by\n",
    "         cooccurrence_matrix()\n",
    "    vocab -- sorted vocabulary created by get_sorted_vocab()\n",
    "\n",
    "    Output\n",
    "    vecs -- dictionary mapping words to their vectors.\n",
    "    \"\"\"    \n",
    "    vecs = {}\n",
    "    for w1 in vocab:\n",
    "        v = []\n",
    "        for w2 in vocab:\n",
    "            wA, wB = sorted([w1, w2])\n",
    "            v.append(d[wA][wB])\n",
    "        vecs[w1] = array(v)\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosim(v1, v2):\n",
    "    \"\"\"Cosine similarity between the two vectors v1 and v2.\"\"\"\n",
    "    num = dot(v1, v2)\n",
    "    den = sqrt(dot(v1, v1)) * sqrt(dot(v2, v2))\n",
    "    if den:\n",
    "        return num/den\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_propagation(cm, vocab, positive, negative, iterations):\n",
    "    \"\"\"\n",
    "    The propagation algorithm employing the cosine values.\n",
    "\n",
    "    Input\n",
    "    cm -- cosine similarity matrix (2-d dictionary) created by cosine_similarity_matrix()\n",
    "    vocab -- vocabulary for cm\n",
    "    positive -- list of strings\n",
    "    negative -- list of strings\n",
    "    iterations -- the number of iterations to perform\n",
    "\n",
    "    Output:\n",
    "    pol -- a dictionary form vocab to floats\n",
    "    \"\"\"\n",
    "    pol = {}    \n",
    "    # Initialize a.\n",
    "    a = defaultdict(lambda : defaultdict(int))\n",
    "    for w1, val_dict in cm.items():\n",
    "        for w2 in val_dict.keys():\n",
    "            if w1 == w2:\n",
    "                a[w1][w2] = 1.0                    \n",
    "    # Propagation.\n",
    "    pol_positive, a = propagate(positive, cm, vocab, a, iterations)\n",
    "    pol_negative, a = propagate(negative, cm, vocab, a, iterations)\n",
    "    beta = sum(pol_positive.values()) / sum(pol_negative.values())\n",
    "    for w in vocab:\n",
    "        pol[w] = pol_positive[w] - (beta * pol_negative[w])\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def propagate(seedset, cm, vocab, a, iterations):\n",
    "    \"\"\"\n",
    "    Propagates the initial seedset, with the cosine measures\n",
    "    determining strength.\n",
    "    \n",
    "    Input\n",
    "    seedset -- list of strings.\n",
    "    cm -- cosine similarity matrix\n",
    "    vocab -- the sorted vocabulary\n",
    "    a -- the new value matrix\n",
    "    iterations -- the number of iteration to perform\n",
    "\n",
    "    Output\n",
    "    pol -- dictionary mapping words to un-corrected polarity scores\n",
    "    a -- the updated matrix\n",
    "    \"\"\"      \n",
    "    for w_i in seedset:\n",
    "        f = {}\n",
    "        f[w_i] = True\n",
    "        for t in range(iterations):\n",
    "            for w_k in cm.keys():\n",
    "                if w_k in f:\n",
    "                    for w_j, val in cm[w_k].items():\n",
    "                        # New value is max{ old-value, cos(k, j) } --- so strength\n",
    "                        # can come from somewhere other th\n",
    "                        a[w_i][w_j] = max([a[w_i][w_j], a[w_i][w_k] * cm[w_k][w_j]])\n",
    "                        f[w_j] = True\n",
    "    # Score tally.\n",
    "    pol = {}\n",
    "    for w in vocab:\n",
    "        pol[w] = sum(a[w_i][w] for a_i in seedset)\n",
    "    return [pol, a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_matrix(vocab, m):\n",
    "    \"\"\"\n",
    "    For display purposes: builds an aligned and neatly rounded version\n",
    "    of the two-dimensional dictionary m, assuming ordered values\n",
    "    vocab. Returns string s.\n",
    "    \"\"\"\n",
    "    s = \"\"\n",
    "    sep = \"\"\n",
    "    col_width = 15\n",
    "    s += \" \".rjust(col_width) + sep.join(map((lambda x : x.rjust(col_width)), vocab)) + \"\\n\"\n",
    "    for w1 in vocab:\n",
    "        row = [w1]\n",
    "        row += [round(m[w1][w2], 2) for w2 in vocab]\n",
    "        s += sep.join(map((lambda x : str(x).rjust(col_width)), row)) + \"\\n\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try Web-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A corpus: 7 texts, each 2-3 words.\n",
    "corpus = (\n",
    "    (\"terrible\", \"horrible\", \"day\"),\n",
    "    (\"horrible\", \"day\"),\n",
    "    (\"terrible\", \"day\"),\n",
    "    (\"superb\", \"memorable\", \"book\"),\n",
    "    (\"superb\", \"book\"),\n",
    "    (\"memorable\", \"book\"),\n",
    "    (\"terrible\", \"memorable\", \"day\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the co-occurrence matrix.\n",
    "d = cooccurrence_matrix(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocab\n",
    "vocab = get_sorted_vocab(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the cosine matrix\n",
    "cm = cosine_similarity_matrix(vocab, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment propagation with simple seed sets.\n",
    "prop = graph_propagation(cm, vocab, [\"superb\"], [\"terrible\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus:\n",
      "\n",
      "terrible horrible day\n",
      "horrible day\n",
      "terrible day\n",
      "superb memorable book\n",
      "superb book\n",
      "memorable book\n",
      "terrible memorable day\n"
     ]
    }
   ],
   "source": [
    "# Display.\n",
    "print(\"Corpus:\\n\")\n",
    "for text in corpus:\n",
    "    print(\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-occurence matrix:\n",
      "\n",
      "                          book            day       horrible      memorable         superb       terrible\n",
      "           book              0              0              0              2              2              0\n",
      "            day              0              0              2              1              0              3\n",
      "       horrible              0              0              0              0              0              1\n",
      "      memorable              0              0              0              0              1              1\n",
      "         superb              0              0              0              0              0              0\n",
      "       terrible              0              0              0              0              0              0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Co-occurence matrix:\\n\")\n",
    "print(format_matrix(vocab, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity matrix:\n",
      "\n",
      "                          book            day       horrible      memorable         superb       terrible\n",
      "           book            1.0           0.19            0.0           0.27           0.32           0.21\n",
      "            day           0.19            1.0           0.36            0.3           0.12           0.24\n",
      "       horrible            0.0           0.36            1.0           0.51            0.0           0.81\n",
      "      memorable           0.27            0.3           0.51            1.0           0.68           0.34\n",
      "         superb           0.32           0.12            0.0           0.68            1.0           0.13\n",
      "       terrible           0.21           0.24           0.81           0.34           0.13            1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity matrix:\\n\")\n",
    "print(format_matrix(vocab, cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propagated polarity: {superb} and {terrible} as seeds, 2 iterations\n",
      "\n",
      "superb 0.739488384054\n",
      "memorable 0.290821527693\n",
      "book 0.115996153404\n",
      "day -0.0675532363583\n",
      "horrible -0.416968403651\n",
      "terrible -0.661784425142\n"
     ]
    }
   ],
   "source": [
    "print(\"Propagated polarity: {superb} and {terrible} as seeds, 2 iterations\\n\")\n",
    "for key, val in sorted(prop.items(), key=itemgetter(1), reverse=True):\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: the code bellow is ready for Python \n",
    "http://sentiment.christopherpotts.net/code-data/webpropagate.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python 3.5]",
   "language": "python",
   "name": "conda-env-Python 3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
